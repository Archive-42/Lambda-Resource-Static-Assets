<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>OVERVIEW</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
</head>
<body>
<h1 id="fx-technical-overview-wip">FX Technical Overview (WIP)</h1>
<p>FX is a toolkit for pass writers to facilitate Python-to-Python transformation of <code>nn.Module</code> instances. This toolkit aims to support a subset of Python language semantics—rather than the whole Python language—to facilitate ease of implementation of transforms. Currently, this feature is under a Beta release and its API may change.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><a href="#fx-technical-overview">FX Technical Overview</a>
<ul>
<li><a href="#table-of-contents">Table of Contents</a></li>
</ul></li>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#use-cases">Use Cases</a></li>
<li><a href="#technical-details">Technical Details</a></li>
</ul></li>
<li><a href="#internal-structure">Internal Structure</a>
<ul>
<li><a href="#graph">Graph</a></li>
<li><a href="#graph-module">Graph Module</a></li>
</ul></li>
<li><a href="#symbolic-tracing">Symbolic Tracing</a>
<ul>
<li><a href="#about">About</a></li>
<li><a href="#tracer">Tracer</a></li>
<li><a href="#proxy">Proxy</a></li>
</ul></li>
<li><a href="#ir">The FX IR</a></li>
<li><a href="#codegen">Transformation and Codegen</a></li>
</ul>
<h1 id="introduction">Introduction</h1>
<h2 id="motivation">Motivation</h2>
<p>TODO</p>
<h2 id="use-cases">Use Cases</h2>
<p>FX should be used by pass writers to provide functionality for capturing and constructing nn.Module code in a structured way. We do not expect end users to utilize FX directly. A useful property of framing FX in this way is that passes can be seen as functions of the form <code>pass(in_mod : nn.Module) -&gt; nn.Module</code>. This means we can create composable pipelines of transformations.</p>
<figure>
<img src="https://i.imgur.com/TzFIYMi.png" title="nn.Module transformation pipeline" alt="An image of a sample nn.Module transformation pipeline that starts with a Quantize transformation, which is then composed with a Split transformation, then a Lower to Accelerator transformation" /><figcaption>An image of a sample nn.Module transformation pipeline that starts with a Quantize transformation, which is then composed with a Split transformation, then a Lower to Accelerator transformation</figcaption>
</figure>
<p>In this example pipeline, we have a Quantize transformation, which is then composed with a Split transformation, then a Lower to Accelerator transformation. Finally, the transformed Modules are compiled with TorchScript for deployment. This last point emphasizes that not only should FX transforms be composable with each other, but their products are composable with other systems like TorchScript compilation or tracing.</p>
<p>By using <code>nn.Module</code> as the interface between passes, FX transforms are interoperable with each other, and the resulting model can be used anywhere an <code>nn.Module</code> can be used.</p>
<h2 id="technical-details">Technical Details</h2>
<p>The following sections will walk us through the components that transform from original <code>torch.nn.Module</code> to FX IR and finally to generated Python code and a GraphModule instance:</p>
<p>FX’s front-end makes use of the dynamic nature of Python to intercept call-sites for various entities (PyTorch operators, Module invocations, and Tensor method invocations). This functionality is exposed through an API called <code>torch.fx.symbolic_trace</code>. We can see how this works by way of an example:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1"><span class="im">import</span> torch</a>
<a class="sourceLine" id="cb1-2" title="2"></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="kw">class</span> MyModule(torch.nn.Module):</a>
<a class="sourceLine" id="cb1-4" title="4">  <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</a>
<a class="sourceLine" id="cb1-5" title="5">    <span class="bu">super</span>().<span class="fu">__init__</span>()</a>
<a class="sourceLine" id="cb1-6" title="6">    <span class="va">self</span>.param <span class="op">=</span> torch.nn.Parameter(</a>
<a class="sourceLine" id="cb1-7" title="7">        torch.rand(<span class="dv">3</span>, <span class="dv">4</span>))</a>
<a class="sourceLine" id="cb1-8" title="8">    <span class="va">self</span>.linear <span class="op">=</span> torch.nn.Linear(<span class="dv">4</span>, <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb1-9" title="9"></a>
<a class="sourceLine" id="cb1-10" title="10">  <span class="kw">def</span> forward(<span class="va">self</span>, x):</a>
<a class="sourceLine" id="cb1-11" title="11">    <span class="cf">return</span> <span class="va">self</span>.linear(x <span class="op">+</span> <span class="va">self</span>.param).clamp(<span class="bu">min</span><span class="op">=</span><span class="fl">0.0</span>, <span class="bu">max</span><span class="op">=</span><span class="fl">1.0</span>)</a>
<a class="sourceLine" id="cb1-12" title="12"></a>
<a class="sourceLine" id="cb1-13" title="13"><span class="im">from</span> torch.fx <span class="im">import</span> symbolic_trace</a>
<a class="sourceLine" id="cb1-14" title="14">module <span class="op">=</span> MyModule()</a>
<a class="sourceLine" id="cb1-15" title="15">symbolic_traced : torch.fx.GraphModule <span class="op">=</span> symbolic_trace(module)</a>
<a class="sourceLine" id="cb1-16" title="16"></a>
<a class="sourceLine" id="cb1-17" title="17"><span class="bu">input</span> <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">4</span>)</a>
<a class="sourceLine" id="cb1-18" title="18">torch.testing.assert_allclose(symbolic_traced(<span class="bu">input</span>), module(<span class="bu">input</span>))</a></code></pre></div>
<p>Here, we set up a simple Module that exercises different language features: fetching a parameter, applying an arithmetic operator, applying a submodule (linear), and applying a Tensor method. <code>symbolic_trace</code> returns an instance of GraphModule, which is in itself a subclass of <code>nn.Module</code>. We can see that the <code>symbolic_traced</code> instance runs and returns the same result as the original module instance module.</p>
<h1 id="internal-structure">Internal Structure</h1>
<h2 id="graph"><a href="https://pytorch.org/docs/master/fx.html#torch.fx.Graph">Graph</a></h2>
<p>TODO</p>
<h2 id="graphmodule"><a href="https://pytorch.org/docs/master/fx.html#torch.fx.GraphModule">GraphModule</a></h2>
<p>TODO</p>
<h1 id="symbolic-tracing">Symbolic Tracing</h1>
<h2 id="tracer"><a href="https://pytorch.org/docs/master/fx.html#torch.fx.Tracer">Tracer</a></h2>
<p><code>Tracer</code> is the class that implements the symbolic tracing functionality of <code>torch.fx.symbolic_trace</code>. A call to <code>symbolic_trace(m)</code> is equivalent to <code>Tracer().trace(m)</code>. Tracer can be subclassed to override various behaviors of the tracing process. The different behaviors that can be overridden are described in the docstrings of the methods on the class.</p>
<p>In the default implementation of <code>Tracer().trace</code>, the tracer first creates Proxy objects for all arguments in the <code>forward</code> function. (This happens in the call to <code>create_args_for_root</code>.) Next, the <code>forward</code> function is called with the new Proxy arguments. As the Proxies flow through the program, they record all the operations (<code>torch</code> function calls, method calls, and operators) that they touch into the growing FX Graph as Nodes.</p>
<h2 id="proxy">Proxy</h2>
<p>Proxy objects are Node wrappers used by the Tracer to record operations seen during symbolic tracing. The mechanism through which Proxy objects record computation is <a href="https://pytorch.org/docs/stable/notes/extending.html#extending-torch"><code>__torch_function__</code></a>. If any custom Python type defines a method named <code>__torch_function__</code>, PyTorch will invoke that <code>__torch_function__</code> implementation when an instance of that custom type is passed to a function in the <code>torch</code> namespace. In FX, when operations on Proxy are dispatched to the <code>__torch_function__</code> handler, the <code>__torch_function__</code> handler records the operation in the Graph as a Node. The Node that was recorded in the Graph is then itself wrapped in a Proxy, facilitating further application of ops on that value.</p>
<p>Consider the following example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">  <span class="kw">class</span> M(torch.nn.Module):</a>
<a class="sourceLine" id="cb2-2" title="2">      <span class="kw">def</span> forward(<span class="va">self</span>, x):</a>
<a class="sourceLine" id="cb2-3" title="3">          <span class="cf">return</span> torch.relu(x)</a>
<a class="sourceLine" id="cb2-4" title="4"></a>
<a class="sourceLine" id="cb2-5" title="5">  m <span class="op">=</span> M()</a>
<a class="sourceLine" id="cb2-6" title="6">  traced <span class="op">=</span> symbolic_trace(m)</a></code></pre></div>
<p>During the call to <code>symbolic_trace</code>, the parameter <code>x</code> is transformed into a Proxy object and the corresponding Node (a Node with op = “placeholder” and target = “x”) is added to the Graph. Then, the Module is run with Proxies as inputs, and recording happens via the <code>__torch_function__</code> dispatch path.</p>
<p>If you’re doing graph transforms, you can wrap your own Proxy method around a raw Node so that you can use the overloaded operators to add additional things to a Graph.</p>
<h1 id="the-fx-ir">The FX IR</h1>
<p>Symbolic tracing captures an intermediate representation (IR), which is represented as a doubly-linked list of Nodes.</p>
<p>Node is the data structure that represents individual operations within a Graph. For the most part, Nodes represent callsites to various entities, such as operators, methods, and Modules (some exceptions include Nodes that specify function inputs and outputs). Each Node has a function specified by its <code>op</code> property. The Node semantics for each value of <code>op</code> are as follows:</p>
<ul>
<li><code>placeholder</code> represents a function input. The <code>name</code> attribute specifies the name this value will take on. <code>target</code> is similarly the name of the argument. <code>args</code> holds either: 1) nothing, or 2) a single argument denoting the default parameter of the function input. <code>kwargs</code> is don’t-care. Placeholders correspond to the function parameters (e.g. <code>x</code>) in the graph printout.</li>
<li><code>get_attr</code> retrieves a parameter from the module hierarchy. <code>name</code> is similarly the name the result of the fetch is assigned to. <code>target</code> is the fully-qualified name of the parameter’s position in the module hierarchy. <code>args</code> and <code>kwargs</code> are don’t-care</li>
<li><code>call_function</code> applies a free function to some values. <code>name</code> is similarly the name of the value to assign to. <code>target</code> is the function to be applied. <code>args</code> and <code>kwargs</code> represent the arguments to the function, following the Python calling convention</li>
<li><code>call_module</code> applies a module in the module hierarchy’s <code>forward()</code> method to given arguments. <code>name</code> is as previous. <code>target</code> is the fully-qualified name of the module in the module hierarchy to call. <code>args</code> and <code>kwargs</code> represent the arguments to invoke the module on, <em>including the self argument</em>.</li>
<li><code>call_method</code> calls a method on a value. <code>name</code> is as similar. <code>target</code> is the string name of the method to apply to the <code>self</code> argument. <code>args</code> and <code>kwargs</code> represent the arguments to invoke the module on, <em>including the self argument</em></li>
<li><code>output</code> contains the output of the traced function in its <code>args[0]</code> attribute. This corresponds to the “return” statement in the Graph printout.</li>
</ul>
<p>To facilitate easier analysis of data dependencies, Nodes have read-only properties <code>input_nodes</code> and <code>users</code>, which specify which Nodes in the Graph are used by this Node and which Nodes use this Node, respectively. Although Nodes are represented as a doubly-linked list, the use-def relationships form an acyclic graph and can be traversed as such.</p>
<h1 id="transformation-and-codegen">Transformation and Codegen</h1>
<p>An invocation of <code>symbolic_traced</code> above requires a valid <code>forward()</code> method to be defined on the Module instance. How does this work? GraphModule actually generates valid Python source code based on the IR it is instantiated with. This can be seen by accessing the code attribute on the GraphModule: <code>print(symbolic_traced.code)</code>.</p>
<p>After symbolic tracing, the code given under <a href="#technical-details">Technical Details</a> is represented as follows:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="kw">def</span> forward(<span class="va">self</span>, x):</a>
<a class="sourceLine" id="cb3-2" title="2">    param <span class="op">=</span> <span class="va">self</span>.param</a>
<a class="sourceLine" id="cb3-3" title="3">    add_1 <span class="op">=</span> x <span class="op">+</span> param<span class="op">;</span>  x <span class="op">=</span> param <span class="op">=</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb3-4" title="4">    linear_1 <span class="op">=</span> <span class="va">self</span>.linear(add_1)<span class="op">;</span>  add_1 <span class="op">=</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb3-5" title="5">    clamp_1 <span class="op">=</span> linear_1.clamp(<span class="bu">min</span> <span class="op">=</span> <span class="fl">0.0</span>, <span class="bu">max</span> <span class="op">=</span> <span class="fl">1.0</span>)<span class="op">;</span>  linear_1 <span class="op">=</span> <span class="va">None</span></a>
<a class="sourceLine" id="cb3-6" title="6">    <span class="cf">return</span> clamp_1</a></code></pre></div>
<p>This is the core of why FX is a Python-to-Python translation toolkit. Outside users can treat the results of FX transformations as they would any other <code>nn.Module</code> instance.</p>
</body>
</html>
