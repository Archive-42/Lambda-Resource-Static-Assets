<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Pytorch-cifar10-SingleNode-DP-GPUCPU</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
</head>
<body>
<h1 id="cifar-10-single-node-dp-job-template">CIFAR-10 Single Node DP Job Template</h1>
<p>This example shows how to train a custom neural network on cifar10 with Pytorch on OpenPAI. In this example, we use the DataParallel.</p>
<p>DataParallel splits your data automatically and sends job orders to multiple models on several GPUs. After each model finishes their job, DataParallel collects and merges the results before returning it to you.</p>
<p>This example program can only run on single-node, but you can choose to use multiple gpus and cpus.</p>
<h2 id="training-data">Training Data</h2>
<p>The training set is using <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> dataset. PyTorch provides CIFAR-10 download in <code>torchvision.datasets.CIFAR10</code> and <em>DataLoader</em> in <code>torch.utils.data.DataLoader</code>.</p>
<h2 id="how-to-use">How to use</h2>
<h3 id="prerequisites">Prerequisites</h3>
<p>N/A</p>
<h3 id="training-command">Training command</h3>
<p>To run the job, you should apply <strong>4 SKU</strong> resources. The training code is as below.</p>
<pre><code>wget https://raw.githubusercontent.com/microsoft/pai/master/examples/Distributed-example/cifar10-single-node-gpus-cpu-DP.py

python cifar10-single-node-gpus-cpu-DP.py --gpuid 0,1,2,3</code></pre>
<h3 id="get-the-result-model">Get the result model</h3>
<p>You can view the training process and result in the logs when training process is finished.</p>
</body>
</html>
